{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe26f15-7e2a-4acf-8293-6f2c6ad0eb51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: opencv-python in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (4.6.0.66)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (1.13.1)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.14.1)\n",
      "Requirement already satisfied: torchsummary in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (1.5.1)\n",
      "Requirement already satisfied: tensorboardX in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (2.6)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (4.63.2)\n",
      "Requirement already satisfied: einops in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (0.6.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (1.4.4)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (1.8.1)\n",
      "Requirement already satisfied: tensorboard in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (2.13.0)\n",
      "Requirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torch->-r requirements.txt (line 3)) (4.4.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 4)) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 4)) (9.2.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboardX->-r requirements.txt (line 6)) (3.20.2)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboardX->-r requirements.txt (line 6)) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 9)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 9)) (2022.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 11)) (2.20.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 11)) (0.7.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 11)) (1.54.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 11)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 11)) (3.4.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 11)) (0.38.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 11)) (2.2.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 11)) (1.4.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 11)) (65.6.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (0.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (4.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (5.3.1)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (1.26.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 11)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 11)) (4.13.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 4)) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 4)) (2.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 11)) (2.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging->tensorboardX->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 11)) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 11)) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f42ceda7-f3f1-4099-b3dd-48b9caf013c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, './models')\n",
    "\n",
    "import maniqa\n",
    "import swin\n",
    "import data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d40561-fb6b-4d06-8110-d4d347925e72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57f4e398-386f-4706-a773-f8a820241a81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from models.maniqa import MANIQA\n",
    "from config import Config\n",
    "from utils.process import RandCrop, ToTensor, Normalize, five_point_crop\n",
    "from utils.process import split_dataset_kadid10k, split_dataset_koniq10k\n",
    "from utils.process import RandRotation, RandHorizontalFlip\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac8c94f-83bb-48fe-bf54-da27591d577b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ca66a2-0342-495e-840f-776a3a57df9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "658a9c18-cb34-41bd-bdaa-882b37802787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_logging(config):\n",
    "    if not os.path.exists(config.log_path): \n",
    "        os.makedirs(config.log_path)\n",
    "    filename = os.path.join(config.log_path, config.log_file)\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        filename=filename,\n",
    "        filemode='w',\n",
    "        format='[%(asctime)s %(levelname)-8s] %(message)s',\n",
    "        datefmt='%Y%m%d %H:%M:%S'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be0266f-a902-4834-a143-be8b0471609e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(epoch, net, criterion, optimizer, scheduler, train_loader):\n",
    "    losses = []\n",
    "    net.train()\n",
    "    # save data for one epoch\n",
    "    pred_epoch = []\n",
    "    labels_epoch = []\n",
    "    \n",
    "    for data in tqdm(train_loader):\n",
    "        x_d = data['d_img_org'].cuda()\n",
    "        labels = data['score']\n",
    "\n",
    "        labels = torch.squeeze(labels.type(torch.FloatTensor)).cuda()  \n",
    "        pred_d = net(x_d)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(torch.squeeze(pred_d), labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # save results in one epoch\n",
    "        pred_batch_numpy = pred_d.data.cpu().numpy()\n",
    "        labels_batch_numpy = labels.data.cpu().numpy()\n",
    "        pred_epoch = np.append(pred_epoch, pred_batch_numpy)\n",
    "        labels_epoch = np.append(labels_epoch, labels_batch_numpy)\n",
    "    \n",
    "    # compute correlation coefficient\n",
    "    rho_s, _ = spearmanr(np.squeeze(pred_epoch), np.squeeze(labels_epoch))\n",
    "    rho_p, _ = pearsonr(np.squeeze(pred_epoch), np.squeeze(labels_epoch))\n",
    "\n",
    "    ret_loss = np.mean(losses)\n",
    "    logging.info('train epoch:{} / loss:{:.4} / SRCC:{:.4} / PLCC:{:.4}'.format(epoch + 1, ret_loss, rho_s, rho_p))\n",
    "\n",
    "    return ret_loss, rho_s, rho_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f86cb0e-1e5a-48d0-be51-da57c9b53fff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_epoch(config, epoch, net, criterion, test_loader):\n",
    "    with torch.no_grad():\n",
    "        losses = []\n",
    "        net.eval()\n",
    "        # save data for one epoch\n",
    "        pred_epoch = []\n",
    "        labels_epoch = []\n",
    "\n",
    "        for data in tqdm(test_loader):\n",
    "            pred = 0\n",
    "            for i in range(config.num_avg_val):\n",
    "                x_d = data['d_img_org'].cuda()\n",
    "                labels = data['score']\n",
    "                labels = torch.squeeze(labels.type(torch.FloatTensor)).cuda()\n",
    "                x_d = five_point_crop(i, d_img=x_d, config=config)\n",
    "                pred += net(x_d)\n",
    "\n",
    "            pred /= config.num_avg_val\n",
    "            # compute loss\n",
    "            loss = criterion(torch.squeeze(pred), labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # save results in one epoch\n",
    "            pred_batch_numpy = pred.data.cpu().numpy()\n",
    "            labels_batch_numpy = labels.data.cpu().numpy()\n",
    "            pred_epoch = np.append(pred_epoch, pred_batch_numpy)\n",
    "            labels_epoch = np.append(labels_epoch, labels_batch_numpy)\n",
    "        \n",
    "        # compute correlation coefficient\n",
    "        rho_s, _ = spearmanr(np.squeeze(pred_epoch), np.squeeze(labels_epoch))\n",
    "        rho_p, _ = pearsonr(np.squeeze(pred_epoch), np.squeeze(labels_epoch))\n",
    "\n",
    "        logging.info('Epoch:{} ===== loss:{:.4} ===== SRCC:{:.4} ===== PLCC:{:.4}'.format(epoch + 1, np.mean(losses), rho_s, rho_p))\n",
    "        return np.mean(losses), rho_s, rho_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fc6eadd-154f-4402-97d2-f5eb547a2244",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525539683/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 116/116 [04:23<00:00,  2.27s/it]\n",
      "100%|██████████| 29/29 [00:27<00:00,  1.06it/s]\n",
      "100%|██████████| 116/116 [04:58<00:00,  2.57s/it]\n",
      "100%|██████████| 29/29 [00:28<00:00,  1.03it/s]\n",
      "100%|██████████| 116/116 [05:02<00:00,  2.61s/it]\n",
      "100%|██████████| 29/29 [00:28<00:00,  1.03it/s]\n",
      "100%|██████████| 116/116 [04:50<00:00,  2.50s/it]\n",
      "100%|██████████| 29/29 [00:23<00:00,  1.24it/s]\n",
      "100%|██████████| 116/116 [04:20<00:00,  2.24s/it]\n",
      "100%|██████████| 29/29 [00:26<00:00,  1.09it/s]\n",
      "100%|██████████| 116/116 [04:44<00:00,  2.45s/it]\n",
      "100%|██████████| 29/29 [00:23<00:00,  1.24it/s]\n",
      "100%|██████████| 116/116 [04:21<00:00,  2.26s/it]\n",
      "100%|██████████| 29/29 [00:23<00:00,  1.24it/s]\n",
      "100%|██████████| 116/116 [04:14<00:00,  2.20s/it]\n",
      "100%|██████████| 29/29 [00:24<00:00,  1.21it/s]\n",
      "100%|██████████| 116/116 [04:40<00:00,  2.42s/it]\n",
      "100%|██████████| 29/29 [00:27<00:00,  1.06it/s]\n",
      "100%|██████████| 116/116 [04:56<00:00,  2.55s/it]\n",
      "100%|██████████| 29/29 [00:27<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    cpu_num = 16\n",
    "    os.environ['OMP_NUM_THREADS'] = str(cpu_num)\n",
    "    os.environ['OPENBLAS_NUM_THREADS'] = str(cpu_num)\n",
    "    os.environ['MKL_NUM_THREADS'] = str(cpu_num)\n",
    "    os.environ['VECLIB_MAXIMUM_THREADS'] = str(cpu_num)\n",
    "    os.environ['NUMEXPR_NUM_THREADS'] = str(cpu_num)\n",
    "    torch.set_num_threads(cpu_num)\n",
    "\n",
    "    setup_seed(20)\n",
    "\n",
    "    # config file\n",
    "    config = Config({\n",
    "        # dataset path\n",
    "        \"dataset_name\": \"clive\",\n",
    "        # \"dataset_name\": \"koniq10k\",\n",
    "\n",
    "        # PIPAL\n",
    "        \"train_dis_path\": \"/mnt/IQA_dataset/PIPAL22/Train_dis/\",\n",
    "        \"val_dis_path\": \"/mnt/IQA_dataset/PIPAL22/Val_dis/\",\n",
    "        \"pipal22_train_label\": \"./data/PIPAL22/pipal22_train.txt\",\n",
    "        \"pipal22_val_txt_label\": \"./data/PIPAL22/pipal22_val.txt\",\n",
    "\n",
    "        # KADID-10K\n",
    "        \"kadid10k_path\": \"/mnt/IQA_dataset/kadid10k/images/\",\n",
    "        \"kadid10k_label\": \"./data/kadid10k/kadid10k_label.txt\",\n",
    "\n",
    "        # KONIQ-10K\n",
    "        # \"koniq10k_path\": \"/mnt/IQA_dataset/1024x768/\",\n",
    "        # \"koniq10k_label\": \"./data/koniq10k/koniq10k_label.txt\",\n",
    "        # KONIQ-10K from here\n",
    "        \"koniq10k_path\": data_path.koniq10k_1024x768,\n",
    "        \"koniq10k_label\": \"./data/koniq10k/koniq10k_label.txt\",\n",
    "        \n",
    "        # clive\n",
    "        \"clive_path\": data_path.clive_images,\n",
    "        \"clive_label\": \"./data/clive/clive_label.txt\",\n",
    "        \n",
    "        # optimization\n",
    "        \"batch_size\": 8,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"weight_decay\": 1e-5,\n",
    "        \n",
    "        # \"n_epoch\": 300,\n",
    "        \"n_epoch\": 10,\n",
    "        \n",
    "        \"val_freq\": 1,\n",
    "        \"T_max\": 50,\n",
    "        \"eta_min\": 0,\n",
    "        \"num_avg_val\": 1, # if training koniq10k, num_avg_val is set to 1\n",
    "        \"num_workers\": 8,\n",
    "        \n",
    "        # data\n",
    "        \"split_seed\": 20,\n",
    "        \"train_keep_ratio\": 1.0,\n",
    "        \"val_keep_ratio\": 1.0,\n",
    "        \"crop_size\": 224,\n",
    "        \"prob_aug\": 0.7,\n",
    "\n",
    "        # model\n",
    "        \"patch_size\": 8,\n",
    "        \"img_size\": 224,\n",
    "        \"embed_dim\": 768,\n",
    "        \"dim_mlp\": 768,\n",
    "        \"num_heads\": [4, 4],\n",
    "        \"window_size\": 4,\n",
    "        \"depths\": [2, 2],\n",
    "        \"num_outputs\": 1,\n",
    "        \"num_tab\": 2,\n",
    "        \"scale\": 0.8,\n",
    "        \n",
    "        # load & save checkpoint\n",
    "        \"model_name\": \"clive-base_s20\",\n",
    "        \"type_name\": \"Clive\",\n",
    "        \"ckpt_path\": \"./output/models/\",               # directory for saving checkpoint\n",
    "        \"log_path\": \"./output/log/\",\n",
    "        \"log_file\": \".log\",\n",
    "        \"tensorboard_path\": \"./output/tensorboard/\"\n",
    "    })\n",
    "    \n",
    "    config.log_file = config.model_name + \".log\"\n",
    "    config.tensorboard_path = os.path.join(config.tensorboard_path, config.type_name)\n",
    "    config.tensorboard_path = os.path.join(config.tensorboard_path, config.model_name)\n",
    "\n",
    "    config.ckpt_path = os.path.join(config.ckpt_path, config.type_name)\n",
    "    config.ckpt_path = os.path.join(config.ckpt_path, config.model_name)\n",
    "\n",
    "    config.log_path = os.path.join(config.log_path, config.type_name)\n",
    "\n",
    "    if not os.path.exists(config.ckpt_path):\n",
    "        os.makedirs(config.ckpt_path)\n",
    "    \n",
    "    if not os.path.exists(config.tensorboard_path):\n",
    "        os.makedirs(config.tensorboard_path)\n",
    "\n",
    "    set_logging(config)\n",
    "    logging.info(config)\n",
    "\n",
    "    writer = SummaryWriter(config.tensorboard_path)\n",
    "\n",
    "    if config.dataset_name == 'kadid10k':\n",
    "        from data.kadid10k.kadid10k import Kadid10k\n",
    "        train_name, val_name = split_dataset_kadid10k(\n",
    "            txt_file_name=config.kadid10k_label,\n",
    "            split_seed=config.split_seed\n",
    "        )\n",
    "        dis_train_path = config.kadid10k_path\n",
    "        dis_val_path = config.kadid10k_path\n",
    "        label_train_path = config.kadid10k_label\n",
    "        label_val_path = config.kadid10k_label\n",
    "        Dataset = Kadid10k\n",
    "    elif config.dataset_name == 'pipal':\n",
    "        from data.PIPAL22.pipal import PIPAL\n",
    "        dis_train_path = config.train_dis_path\n",
    "        dis_val_path = config.val_dis_path\n",
    "        label_train_path = config.pipal22_train_label\n",
    "        label_val_path = config.pipal22_val_txt_label\n",
    "        Dataset = PIPAL\n",
    "    elif config.dataset_name == 'koniq10k':\n",
    "        from data.koniq10k.koniq10k import Koniq10k\n",
    "        train_name, val_name = split_dataset_koniq10k(\n",
    "            txt_file_name=config.koniq10k_label,\n",
    "            split_seed=config.split_seed\n",
    "        )\n",
    "        dis_train_path = config.koniq10k_path\n",
    "        dis_val_path = config.koniq10k_path\n",
    "        label_train_path = config.koniq10k_label\n",
    "        label_val_path = config.koniq10k_label\n",
    "        Dataset = Koniq10k\n",
    "    elif config.dataset_name == 'clive':\n",
    "        from data.clive.clive import Clive\n",
    "        train_name, val_name = split_dataset_koniq10k(\n",
    "            txt_file_name=config.clive_label,\n",
    "            split_seed=config.split_seed\n",
    "        )\n",
    "        dis_train_path = config.clive_path\n",
    "        dis_val_path = config.clive_path\n",
    "        label_train_path = config.clive_label\n",
    "        label_val_path = config.clive_label\n",
    "        Dataset = Clive\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # data load\n",
    "    train_dataset = Dataset(\n",
    "        dis_path=dis_train_path,\n",
    "        txt_file_name=label_train_path,\n",
    "        list_name=train_name,\n",
    "        transform=transforms.Compose([RandCrop(patch_size=config.crop_size), \n",
    "            Normalize(0.5, 0.5), RandHorizontalFlip(prob_aug=config.prob_aug), ToTensor()]),\n",
    "        keep_ratio=config.train_keep_ratio\n",
    "    )\n",
    "    val_dataset = Dataset(\n",
    "        dis_path=dis_val_path,\n",
    "        txt_file_name=label_val_path,\n",
    "        list_name=val_name,\n",
    "        transform=transforms.Compose([RandCrop(patch_size=config.crop_size),\n",
    "            Normalize(0.5, 0.5), ToTensor()]),\n",
    "        keep_ratio=config.val_keep_ratio\n",
    "    )\n",
    "\n",
    "    logging.info('number of train scenes: {}'.format(len(train_dataset)))\n",
    "    logging.info('number of val scenes: {}'.format(len(val_dataset)))\n",
    "\n",
    "    # load the data\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=config.batch_size,\n",
    "        num_workers=config.num_workers, drop_last=True, shuffle=True)\n",
    "\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=config.batch_size,\n",
    "        num_workers=config.num_workers, drop_last=True, shuffle=False)\n",
    "\n",
    "    # model defination\n",
    "    net = MANIQA(embed_dim=config.embed_dim, num_outputs=config.num_outputs, dim_mlp=config.dim_mlp,\n",
    "        patch_size=config.patch_size, img_size=config.img_size, window_size=config.window_size,\n",
    "        depths=config.depths, num_heads=config.num_heads, num_tab=config.num_tab, scale=config.scale)\n",
    "\n",
    "    logging.info('{} : {} [M]'.format('#Params', sum(map(lambda x: x.numel(), net.parameters())) / 10 ** 6))\n",
    "\n",
    "    net = nn.DataParallel(net)\n",
    "    net = net.cuda()\n",
    "\n",
    "    # loss function\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        net.parameters(),\n",
    "        lr=config.learning_rate,\n",
    "        weight_decay=config.weight_decay,\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.T_max, eta_min=config.eta_min)\n",
    "\n",
    "    # train & validation\n",
    "    losses, scores = [], []\n",
    "    best_srocc = 0\n",
    "    best_plcc = 0\n",
    "    main_score = 0\n",
    "    for epoch in range(0, config.n_epoch):\n",
    "        start_time = time.time()\n",
    "        logging.info('Running training epoch {}'.format(epoch + 1))\n",
    "        loss_val, rho_s, rho_p = train_epoch(epoch, net, criterion, optimizer, scheduler, train_loader)\n",
    "\n",
    "        writer.add_scalar(\"Train_loss\", loss_val, epoch)\n",
    "        writer.add_scalar(\"SRCC\", rho_s, epoch)\n",
    "        writer.add_scalar(\"PLCC\", rho_p, epoch)\n",
    "\n",
    "        if (epoch + 1) % config.val_freq == 0:\n",
    "            logging.info('Starting eval...')\n",
    "            logging.info('Running testing in epoch {}'.format(epoch + 1))\n",
    "            loss, rho_s, rho_p = eval_epoch(config, epoch, net, criterion, val_loader)\n",
    "            logging.info('Eval done...')\n",
    "\n",
    "            if rho_s + rho_p > main_score:\n",
    "                main_score = rho_s + rho_p\n",
    "                best_srocc = rho_s\n",
    "                best_plcc = rho_p\n",
    "\n",
    "                logging.info('======================================================================================')\n",
    "                logging.info('============================== best main score is {} ================================='.format(main_score))\n",
    "                logging.info('======================================================================================')\n",
    "\n",
    "                # save weights\n",
    "                model_name = \"epoch{}.pt\".format(epoch + 1)\n",
    "                model_save_path = os.path.join(config.ckpt_path, model_name)\n",
    "                torch.save(net.module.state_dict(), model_save_path)\n",
    "                logging.info('Saving weights and model of epoch{}, SRCC:{}, PLCC:{}'.format(epoch + 1, best_srocc, best_plcc))\n",
    "        \n",
    "        logging.info('Epoch {} done. Time: {:.2}min'.format(epoch + 1, (time.time() - start_time) / 60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
